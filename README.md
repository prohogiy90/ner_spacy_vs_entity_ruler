## В данном репозитории приложено решение задачи извлечения фрагментов из текстов по заданной метке. Решение основано на построении модели Spacy с обучением компонента NER и добавлением пользовательских шаблонов для извлечения сущностей с помощью компонента EntityRuler.

# Постановка задачи
В Контуре мы много работаем с документами: арбитражные иски, госзакупки, исполнительные производства. В данном задании мы предлагаем вам сделать модель, которая поможет отделу госзакупок извлекать 
нужный кусок текста из документа для того, чтобы сформировать анкету заявки. То, какой именно фрагмент текста нужно извлечь, зависит от пункта анкеты, соответствующего документу.
Всего в каждом документе, с которыми вы будет работать, есть 1 из 2-х пунктов анкеты, по которым необходимо извлекать кусочки из текста:
- обеспечение исполнения контракта
- обеспечение гарантийных обязательств

Соответственно, ваша модель, принимая на вход `текст документа` и `наименование одного из двух пунктов`, должна возвращать `соответствующий кусочек текста из текста документа`.

# Данные

### train.json 
Данные для обучения в формате json имеют следующие поля:
- `id`: int - id документа
-  `text`: str - текст документа, в котором может содержаться фрагмент текста, соответствующий пункту анкеты из поля `label`
- `label`: str - название пункта анкеты. Может принимать одно из двух значений: `обеспечение исполнения контракта` или `обеспечение гарантийных обязательств`
- `extracted_part`: dict следующего формата:
    ```
    {
        'text': [фрагмент текста из поля `text`, соответствующий пункту анкеты], 
        'answer_start': [индекс символа начала фрагмента текста в тексте документа],
        'answer_end': [индекс символа конца фрагмента текста в тексте документа]
    }
   ```
  
### test.json

Для демонстрации работы модели используйте данные из файла `test.json`. В нем есть все те же поля, что и в файле `train.json`, кроме поля `extracted_part` - именно его вам и нужно будет добавить,
для того, чтобы мы смогли оценить качество вашей модели.

##### Тестовое задание

Для выполнения тестового задания требуется разработать модель, которая будет способна по паре `текст документа` и `пункт анкеты` извлекать из текста документа нужный фрагмент текста. 
Обучив модель, добавьте в файл `test.json` поле `extracted_part` в том же формате, что и в файле `train.json`. Новый файл назовите `predictions.json`

# Критерии оценки
1. Для оценки финального решения будет использоваться метрика `Accuracy`: доля наблюдений, в которых извлеченный моделью фрагмент текста полностью соответствует фактически
   требуемому фрагменту.
2. Чистота кода, оформление и понятность исследования.

# Решение
В рамках исследования и подбора оптимальной модели, опробованы также модели Flair и разработана модель Tensorflow со слоями Embedding + BiLSTM, которые к сожалению, не дали достаточно высокой результативности, поэтому решено остановиться на модели Spacy.

Архитектура модели:
1. Модель создана на базе предобученной модели 'ru_core_news_lg' (элементы пайплайна 'tok2vec' и 'morphologizer')
2. Создан пользовательский токенайзер для разделения текстов на токены с учетом особенностей представленных документов
3. Добавлен пользовательский компонент NER, который обучен на представленных данных.
4. Создан пользовательский компонент EntityRuler для поиска извлекаемых сущностей по шаблонам для повышения точности.

Метрика accuracy модели на тренировочной и валидационной выборках:

#### модель без компонента EntityRuler (только NER) - train_acc = 0.9401, val_acc=0.8;
#### модель с компонентом EntityRuler до NER - train_acc = 0.9642, val_acc=0.9278.

Архив с сохраненной моделью можно найти по ссылке (487Мб)
#### https://drive.google.com/file/d/1JQ4dpMn9cSgeAh0UzX8bXt6Hkan-AMoT/view?usp=share_link

Также можно сделать предположение, что есть возможность увеличить точность модели в случае увеличения количества тренировочных данных (так как многие извлекаемые сущности имеют подобную синтаксическую конструкцию, при этом некоторые сущности встречаются в единичных экземплярах), а также при улучшении качества разметки данных, так как в некоторых случаях конец извлеченного фрагмента размечен в середине непрерывных последовательностей символов, например нижнего подчеркивания.
